{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c114aa-be4a-4519-91cf-f22192699d6b",
   "metadata": {},
   "source": [
    "#### Assignment_No 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7947130d-2258-434f-a232-f6cc57c7a334",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90ab6ed8-735f-456c-a113-a7379ae5384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prepare a model for glass classification using Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Description:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RI : refractive index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Na: Sodium (unit measurement: weight percent i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mg: Magnesium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI: Aluminum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Si: Silicon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K:Potassium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ca: Calcium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ba: Barium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fe: Iron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type: Type of glass: (class attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1 -- building_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2 --building_windows_non_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3 --vehicle_windows_float_processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4 --vehicle_windows_non_float_processed (none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5 --containers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6 --tableware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7 --headlamps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prepare a model for glass classification using Random Forest\n",
       "0                                   Data Description:          \n",
       "1                               RI : refractive index          \n",
       "2   Na: Sodium (unit measurement: weight percent i...          \n",
       "3                                       Mg: Magnesium          \n",
       "4                                        AI: Aluminum          \n",
       "5                                         Si: Silicon          \n",
       "6                                         K:Potassium          \n",
       "7                                         Ca: Calcium          \n",
       "8                                          Ba: Barium          \n",
       "9                                            Fe: Iron          \n",
       "10                                                NaN          \n",
       "11             Type: Type of glass: (class attribute)          \n",
       "12              1 -- building_windows_float_processed          \n",
       "13           2 --building_windows_non_float_processed          \n",
       "14                3 --vehicle_windows_float_processed          \n",
       "15   4 --vehicle_windows_non_float_processed (none...          \n",
       "16                                     5 --containers          \n",
       "17                                      6 --tableware          \n",
       "18                                      7 --headlamps          "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\Random Forest (2)\\Random Forest\\glass.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a0b92-0ba2-40fa-8dca-8cd9ef7c1b62",
   "metadata": {},
   "source": [
    "#### 1. Exploratory Data Analysis (EDA):\n",
    "\n",
    "Perform exploratory data analysis to understand the structure of the dataset.\n",
    "Check for missing values, outliers, inconsistencies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cbfde8-2ae5-402a-aa8e-f128c7f06297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prepare a model for glass classification using Random Forest\n",
      "0                                  Data Description:          \n",
      "1                              RI : refractive index          \n",
      "2  Na: Sodium (unit measurement: weight percent i...          \n",
      "3                                      Mg: Magnesium          \n",
      "4                                       AI: Aluminum          \n",
      "Missing values in each column:\n",
      " Prepare a model for glass classification using Random Forest    1\n",
      "dtype: int64\n",
      "Summary statistics:\n",
      "        Prepare a model for glass classification using Random Forest\n",
      "count                                                  18          \n",
      "unique                                                 18          \n",
      "top                                     Data Description:          \n",
      "freq                                                    1          \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\Random Forest (2)\\Random Forest\\glass.xlsx\")\n",
    "data\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for outliers\n",
    "# You can visualize outliers using box plots or detect them using statistical methods like Z-score or IQR\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics:\\n\", data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cce3a-ba91-4d8a-bed2-99b15edde9b2",
   "metadata": {},
   "source": [
    "#### 2: Data Visualization:\n",
    "\n",
    "Create visualizations such as histograms, box plots, or pair plots to visualize the distributions and relationships between features.\n",
    "Analyze any patterns or correlations observed in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe716c3-24bb-4c71-a008-fcf55b022722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prepare a model for glass classification using Random Forest\n",
      "0                                  Data Description:          \n",
      "1                              RI : refractive index          \n",
      "2  Na: Sodium (unit measurement: weight percent i...          \n",
      "3                                      Mg: Magnesium          \n",
      "4                                       AI: Aluminum          \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                        Non-Null Count  Dtype \n",
      "---  ------                                                        --------------  ----- \n",
      " 0   Prepare a model for glass classification using Random Forest  18 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 284.0+ bytes\n",
      "None\n",
      "Column Names: Index(['Prepare a model for glass classification using Random Forest'], dtype='object')\n",
      "Error: 'glass_type' not found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the data\n",
    "data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\Random Forest (2)\\Random Forest\\glass.xlsx\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Verify column names\n",
    "print(\"Column Names:\", data.columns)\n",
    "\n",
    "# Ensure the target column exists\n",
    "target_column = 'glass_type'\n",
    "if target_column not in data.columns:\n",
    "    print(f\"Error: '{target_column}' not found in the DataFrame.\")\n",
    "    # If the column name is different, update the target_column variable accordingly\n",
    "    # target_column = 'correct_target_column_name'\n",
    "else:\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X = data.drop(columns=target_column)\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76664a-c266-4d93-813b-8e9fbf3c7b27",
   "metadata": {},
   "source": [
    "##### 3: Data Preprocessing\n",
    "\n",
    "1. Check for missing values in the dataset and decide on a strategy for handling them.Implement the chosen strategy (e.g., imputation or removal) and explain your reasoning.\n",
    "2. If there are categorical variables, apply encoding techniques like one-hot encoding to convert them into numerical format.\n",
    "3. Apply feature scaling techniques such as standardization or normalization to ensure that all features are on a similar scale. Handling the imbalance data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6b51f6-f770-4fce-9ba6-27f86f3eacf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "  Prepare a model for glass classification using Random Forest\n",
      "0                                  Data Description:          \n",
      "1                              RI : refractive index          \n",
      "2  Na: Sodium (unit measurement: weight percent i...          \n",
      "3                                      Mg: Magnesium          \n",
      "4                                       AI: Aluminum          \n",
      "\n",
      "Column names:\n",
      "Index(['Prepare a model for glass classification using Random Forest'], dtype='object')\n",
      "\n",
      "Data types of each column:\n",
      "Prepare a model for glass classification using Random Forest    object\n",
      "dtype: object\n",
      "\n",
      "Missing values in each column:\n",
      "Prepare a model for glass classification using Random Forest    19\n",
      "dtype: int64\n",
      "\n",
      "Shape of the data before imputation: (19, 1)\n",
      "\n",
      "Columns with all NaN values:\n",
      "    Prepare a model for glass classification using Random Forest\n",
      "0                                                 NaN           \n",
      "1                                                 NaN           \n",
      "2                                                 NaN           \n",
      "3                                                 NaN           \n",
      "4                                                 NaN           \n",
      "5                                                 NaN           \n",
      "6                                                 NaN           \n",
      "7                                                 NaN           \n",
      "8                                                 NaN           \n",
      "9                                                 NaN           \n",
      "10                                                NaN           \n",
      "11                                                NaN           \n",
      "12                                                NaN           \n",
      "13                                                NaN           \n",
      "14                                                NaN           \n",
      "15                                                NaN           \n",
      "16                                                NaN           \n",
      "17                                                NaN           \n",
      "18                                                NaN           \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Impute and check the shape again\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m data_imputed_array \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mShape of the imputed data array:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_imputed_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Ensure the imputed array has the same number of columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    382\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter was deprecated in version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    388\u001b[0m     )\n\u001b[1;32m--> 390\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, in_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:344\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_fit:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;66;03m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_dtype \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:327\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    324\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    328\u001b[0m         X,\n\u001b[0;32m    329\u001b[0m         reset\u001b[38;5;241m=\u001b[39min_fit,\n\u001b[0;32m    330\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    331\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    332\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    333\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[0;32m    334\u001b[0m     )\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"C:\\Users\\Laptop\\Downloads\\Random Forest (2)\\Random Forest\\glass.xlsx\")\n",
    "\n",
    "# Check the first few rows of the dataset to understand its structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display column names to ensure 'Type' is correct\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types of each column:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Ensure all columns are numeric, replacing non-numeric entries with NaNs\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Check shape before imputation\n",
    "print(\"\\nShape of the data before imputation:\", data.shape)\n",
    "\n",
    "# Ensure there are no entirely empty columns\n",
    "print(\"\\nColumns with all NaN values:\")\n",
    "print(data.loc[:, data.isna().all()])\n",
    "\n",
    "# Drop entirely empty columns\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Impute missing values for numerical features with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Impute and check the shape again\n",
    "data_imputed_array = imputer.fit_transform(data)\n",
    "print(\"\\nShape of the imputed data array:\", data_imputed_array.shape)\n",
    "\n",
    "# Ensure the imputed array has the same number of columns\n",
    "data_imputed = pd.DataFrame(data_imputed_array, columns=data.columns)\n",
    "\n",
    "# Verify the imputation\n",
    "print(\"\\nFirst few rows after imputation:\")\n",
    "print(data_imputed.head())\n",
    "\n",
    "# Apply feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data_array = scaler.fit_transform(data_imputed.drop(columns=['Type']))\n",
    "scaled_data = pd.DataFrame(scaled_data_array, columns=data_imputed.drop(columns=['Type']).columns)\n",
    "\n",
    "# Add the target variable back to the scaled DataFrame\n",
    "scaled_data['Type'] = data_imputed['Type']\n",
    "\n",
    "# Verify the scaled data\n",
    "print(\"\\nFirst few rows after scaling:\")\n",
    "print(scaled_data.head())\n",
    "\n",
    "# Assuming 'Type' is the target variable\n",
    "X = scaled_data.drop(columns=['Type'])  # Features\n",
    "y = scaled_data['Type']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635eeec-b770-4aff-aba4-1bccff1f8c35",
   "metadata": {},
   "source": [
    "#### 4: Random Forest Model Implementation\n",
    "1. Divide the data into train and test split.\n",
    "2. Implement a Random Forest classifier using Python and a machine learning library like scikit-learn.\n",
    "3. Train the model on the train dataset. Evaluate the performance on test data using metrics like accuracy, precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36370e3d-f090-4754-a779-08b2258d46db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Define the data manually based on the provided description\n",
    "data = {\n",
    "    'RI': [1.52101, 1.51761, 1.51618, 1.51766, 1.51742, 1.51596, 1.51743, 1.51756, 1.51918, 1.51755],\n",
    "    'Na': [13.64, 13.89, 13.53, 13.21, 13.29, 13.02, 13.30, 13.15, 13.90, 13.44],\n",
    "    'Mg': [4.49, 3.60, 3.55, 3.69, 3.60, 3.61, 3.60, 3.61, 3.58, 3.61],\n",
    "    'Al': [1.10, 1.36, 1.54, 1.29, 1.35, 1.62, 1.14, 1.05, 1.32, 1.34],\n",
    "    'Si': [71.78, 72.73, 72.99, 72.61, 72.64, 72.51, 73.09, 72.08, 72.99, 72.28],\n",
    "    'K': [0.06, 0.48, 0.39, 0.57, 0.34, 0.57, 0.37, 0.56, 0.57, 0.57],\n",
    "    'Ca': [8.75, 7.83, 7.78, 8.22, 8.24, 8.30, 8.44, 8.38, 8.28, 8.33],\n",
    "    'Ba': [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    'Fe': [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    'Type': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('Type', axis=1)\n",
    "y = df['Type']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# For a more detailed report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd69f73-27da-4022-8e0c-e3362b068bad",
   "metadata": {},
   "source": [
    "#### 5: Bagging and Boosting Methods\n",
    "Apply the Bagging and Boosting methods and compare the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5fa00ab-51ee-47c5-8e33-697bb0ac8117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Example data based on the provided description\n",
    "data = {\n",
    "    'RI': [1.52101, 1.51761, 1.51618, 1.51766, 1.51742],\n",
    "    'Na': [13.64, 13.89, 13.53, 13.21, 13.29],\n",
    "    'Mg': [4.49, 3.60, 3.55, 3.69, 3.60],\n",
    "    'Al': [1.10, 1.36, 1.54, 1.29, 1.35],\n",
    "    'Si': [71.78, 72.73, 72.99, 72.61, 72.64],\n",
    "    'K': [0.06, 0.48, 0.39, 0.57, 0.34],\n",
    "    'Ca': [8.75, 7.83, 7.78, 8.22, 8.24],\n",
    "    'Ba': [0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    'Fe': [0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    'Type': [1, 1, 2, 2, 3]  # Example target variable (replace with your actual target variable)\n",
    "}\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('Type', axis=1)\n",
    "y = df['Type']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c658945-990d-4510-8db7-105fb41146fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
